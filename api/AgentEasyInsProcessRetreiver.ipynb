{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOpw--87wvkW"
      },
      "source": [
        "Now we'll build Data, but as an LLM Agent that can use tools outside of the LLM. In addition to using RAG to access \"long term memory\" of everything Data ever said in tha past, we'll give him a couple of additional capabilities: performing numeric calculations (which LLM's tend to struggle with on their own,) and access current information via a web search.\n",
        "\n",
        "We will start by parsing the original scripts and extracting lines spoken by Data. As before, you will need to upload all of the script files into a tng folder within your sample_data folder in your CoLab workspace first.\n",
        "\n",
        "An archive can be found at https://www.st-minutiae.com/resources/scripts/ (look for \"All TNG Epsiodes\"), but you could easily adapt this to read scripts from your favorite character from your favorite TV show or movie instead.\n",
        "\n",
        "We've done all of this before, so I'm combining all of the code to load up Data's past lines into a vector store together below. We'll pick up again as we incorporate this into an agent. If you need an explanation of how we are populating this vector store, refer to the earlier RAG exercises in the course.\n",
        "\n",
        "Also be sure to provide your own OpenAI secret key. Click on the little key icon in CoLab and add a \"secret\" for OPENAI_API_KEY that points to your secret key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz9yfjGCV52F",
        "outputId": "70e32c4e-8620-4086-e0dc-24d95a79ffee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (2.11.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: certifi in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: langchain_openai in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (1.1.3)\n",
            "Requirement already satisfied: langchain_experimental in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.3 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain_openai) (2.11.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: langchain-community<1.0.0,>=0.4.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain_experimental) (0.4.1)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.0.34)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.10.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (8.2.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.4.59)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.26.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.3->langchain_openai) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.3->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.3->langchain_openai) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.3->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.3->langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.2.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain_openai) (3.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.3->langchain_openai) (2.1)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.3->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.3->langchain_openai) (2.20.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.21.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (3.0.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain_openai) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dinesh\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain_experimental) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai --upgrade\n",
        "!pip install langchain_openai langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLjupJ8rLXr6",
        "outputId": "10c735d1-a829-4a89-8a73-e469e07886bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lines: Handling insurance claims can often seem overwhelming, but with the right guidance and tools, it doesn’t have to be. At Chenango Brokers, we know the challenges you face and are committed to making the process as smooth and efficient as possible. This guide is designed to provide you with practical insights and strategies to navigate the complex world of insurance claims handling with confidence.\n",
            "\n",
            "Extracted 0 dialogue lines for Agent\n",
            "dialogues 1: Handling insurance claims can often seem overwhelming, but with the right guidance and tools, it doesn’t have to be. At Chenango Brokers, we know the challenges you face and are committed to making the process as smooth and efficient as possible. This guide is designed to provide you with practical insights and strategies to navigate the complex world of insurance claims handling with confidence.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dinesh\\AppData\\Local\\Temp\\ipykernel_27068\\399447982.py:104: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
            "  index = VectorstoreIndexCreator(embedding=embeddings).from_documents(docs)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import openai\n",
        "\n",
        "from langchain_classic.indexes import VectorstoreIndexCreator\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "dialogues = []\n",
        "\n",
        "def strip_parentheses(s: str) -> str:\n",
        "    \"\"\"Remove parentheses and their contents from string\"\"\"\n",
        "    return re.sub(r'\\(.*?\\)', '', s)\n",
        "\n",
        "def is_single_word_all_caps(s: str) -> bool:\n",
        "    \"\"\"Check if string is a single word in all caps (character name)\"\"\"\n",
        "    words = s.split()\n",
        "    \n",
        "    if len(words) != 1:\n",
        "        return False\n",
        "    \n",
        "    # Make sure it isn't a line number\n",
        "    if bool(re.search(r'\\d', words[0])):\n",
        "        return False\n",
        "    \n",
        "    return words[0].isupper()\n",
        "\n",
        "def extract_character_lines(file_path: str, dialoguesLines: list):\n",
        "    \"\"\"Extract dialogue lines for a specific character from script file\"\"\"\n",
        "    lines = []\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as script_file:\n",
        "            lines = script_file.readlines()\n",
        "            print(f\"lines: {lines[0]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        return\n",
        "    \n",
        "    # is_character_line = False\n",
        "    # current_line = ''\n",
        "    # current_character = ''\n",
        "    \n",
        "    # for line in lines:\n",
        "    #     stripped_line = line.strip()\n",
        "    #     if is_single_word_all_caps(stripped_line):\n",
        "    #         is_character_line = True\n",
        "    #         current_character = stripped_line\n",
        "    #     elif (line.strip() == '') and is_character_line:\n",
        "    #         is_character_line = False\n",
        "    #         dialog_line = strip_parentheses(current_line).strip()\n",
        "    #         dialog_line = dialog_line.replace('\"', \"'\")\n",
        "    #         if current_character == character_name and len(dialog_line) > 0:\n",
        "    #             dialogues.append(dialog_line)\n",
        "    #         current_line = ''\n",
        "    #     elif is_character_line:\n",
        "    #         current_line += line.strip() + ' '\n",
        "\n",
        "    for line in lines:\n",
        "        stripped_line = line.strip()        \n",
        "        # dialog_line = strip_parentheses(current_line).strip()\n",
        "        # dialog_line = dialog_line.replace('\"', \"'\")\n",
        "        dialogues.append(stripped_line)\n",
        "        # current_line = ''\n",
        "\n",
        "def process_directory(directory_path: str) -> list:\n",
        "    \"\"\"Process all script files in directory and extract character lines\"\"\"\n",
        "    dialogues = []\n",
        "    \n",
        "    if not os.path.exists(directory_path):\n",
        "        print(f\"Warning: Directory {directory_path} does not exist\")\n",
        "    \n",
        "    for filename in os.listdir(directory_path):\n",
        "        file_path = os.path.join(directory_path, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            extract_character_lines(file_path, dialogues)\n",
        "    \n",
        "    print(f\"Extracted {len(dialogues)} dialogue lines for Agent\")\n",
        "\n",
        "process_directory(\"./sample_data/AgentProcess\")\n",
        "\n",
        "# Access the API key from the environment variable\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "tavily_api_key = os.getenv('TAVILY_API_KEY')\n",
        "\n",
        "# Initialize the OpenAI API client\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# Write our extracted lines for Data into a single file, to make\n",
        "# life easier for langchain.\n",
        "print(f\"dialogues 1: {dialogues[0]}\")\n",
        "with open(\"./sample_data/AgentProcess/Agent_process.txt\", \"w+\") as f:\n",
        "    for line in dialogues:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "\n",
        "text_splitter = SemanticChunker(OpenAIEmbeddings(openai_api_key=openai_api_key), breakpoint_threshold_type=\"percentile\")\n",
        "with open(\"./sample_data/AgentProcess/Agent_process.txt\") as f:\n",
        "  data_lines = f.read()\n",
        "docs = text_splitter.create_documents([data_lines])\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "index = VectorstoreIndexCreator(embedding=embeddings).from_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRAwlQ3Fpv0_"
      },
      "source": [
        "Next we will create a langchain retriever to access this vector store that knows about Data. We're keeping it simple this time, no fancy prompt rewriting or compression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BliWKpH2aezr"
      },
      "outputs": [],
      "source": [
        "from langchain_classic.chains import create_retrieval_chain\n",
        "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0)\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an insurance Sales Agent working for LivEasy Insurance, trying to sell insurance to the customer. \"\n",
        "    \"Use the given context to get information about the insurance process, claim process, quote process \"\n",
        "    \"Use three sentence maximum and keep the answer concise. \"\n",
        "    \"Context: {context}\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retriever=index.vectorstore.as_retriever(search_kwargs={'k': 10})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total chunks created: 5\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Handling insurance claims can often seem overwhelming, but with the right guidance and tools, it doesn’t have to be. At Chenango Brokers, we know the challenges you face and are committed to making th\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Your clients rely on you during their most vulnerable moments. By being transparent, empathetic, and proactive, you can build a solid foundation of trust. This trust is vital for client retention and \n",
            "\n",
            "--- Chunk 3 ---\n",
            "Even with the best preparation, challenges can arise. Here are some common issues and how to handle them:\n",
            "Delays and denials are frustrating for everyone involved. Keep your clients informed about pot\n"
          ]
        }
      ],
      "source": [
        "# Cell: Inspect chunks\n",
        "print(f\"Total chunks created: {len(docs)}\")\n",
        "for i, doc in enumerate(docs[:3]):  # Show first 3 chunks\n",
        "    print(f\"\\n--- Chunk {i+1} ---\")\n",
        "    print(doc.page_content[:200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTqVeetbYwJS"
      },
      "source": [
        "Let's make sure it works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V52rl7XX1fb",
        "outputId": "3280bfad-6ad7-4fb9-a1dc-6f78c44d5b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found results:\n",
            "waivers & disclaimers? Business Insurance,Vehicle Insurance, What is your credit rating? Business Insurance,Vehicle Insurance, Have you experienced any financial difficulties or bankruptcies? Business Insurance,What is the reason for seeking new insurance coverage? Business Insurance, How often do you conduct safety audits? Business Insurance, Have you experienced any data breaches? What have you done to safeguard data? Business Insurance, Is your work seasonally impacted? Business Insurance,Vehicle Insurance, may also request bank statements.\n"
          ]
        }
      ],
      "source": [
        "# retriever.invoke(\"LiveEasy insurance\")[0]\n",
        "\n",
        "results = retriever.invoke(\"What information you need for Business insurance?\")\n",
        "\n",
        "if results:\n",
        "    print(\"Found results:\")\n",
        "    print(results[0].page_content)\n",
        "else:\n",
        "    print(\"No results found. Try a different query.\")\n",
        "    \n",
        "    # Try with insurance-related query\n",
        "    results2 = retriever.invoke(\"insurance\")\n",
        "    if results2:\n",
        "        print(\"\\nTrying 'insurance' query:\")\n",
        "        print(results2[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkOevSK1Yxs6"
      },
      "source": [
        "Now we will create a tool from this retriever that our agent can use. We'll let it know that it can answer questions about Data. Think of this as the agent's \"long term memory.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YW4kh3wqYBxz"
      },
      "outputs": [],
      "source": [
        "from langchain_classic.tools.retriever import create_retriever_tool\n",
        "\n",
        "retriever_tool_InsProcess = create_retriever_tool(\n",
        "    retriever, \"Agent_Process\",\n",
        "    \"Search for information about Insurance Process, claim process while talking to a user\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
